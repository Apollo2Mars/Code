{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://blog.csdn.net/qq_32458499/article/details/78856530\n",
    "https://blog.csdn.net/feixiang7701/article/details/81611356\n",
    "# 四种迭代器\n",
    "# https://www.jianshu.com/p/5f9aca0a14fb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 固定长度\n",
    "\n",
    "# input_x = [np.asarray([1,2,3]), np.asarray([4,5]),[6], [7,8], [9]]\n",
    "input_x = [[1,2,3],[4,5,6],[7,8,9]]\n",
    "# input_x = np.asarray(input_x)\n",
    "# input_x = np.asarray(range(0, 18))\n",
    "input_y = input_x\n",
    "\n",
    "data_loader = tf.data.Dataset.from_tensor_slices(\n",
    "    {'text': np.asarray(input_x),\n",
    "     'label': np.asarray(input_y)}).batch(2)\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "iterator = data_loader.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        sample_batched = session.run(one_element)\n",
    "        inputs = sample_batched['text']\n",
    "        labels = sample_batched['label']\n",
    "        print(\">>> inputs\", inputs)\n",
    "        print(\">>> labels\", labels)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Expected binary or unicode string, got [1, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-9932fe53362b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m data_loader = tf.data.Dataset.from_tensor_slices(\n\u001b[1;32m     11\u001b[0m     {'text': np.asarray(input_x),\n\u001b[0;32m---> 12\u001b[0;31m      'label': np.asarray(input_y)}).batch(2)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    287\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \"\"\"\n\u001b[0;32m--> 289\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m   1563\u001b[0m           if sparse_tensor_lib.is_sparse(t) else ops.convert_to_tensor(\n\u001b[1;32m   1564\u001b[0m               t, name=\"component_%d\" % i)\n\u001b[0;32m-> 1565\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m       ])\n\u001b[1;32m   1567\u001b[0m       \u001b[0mflat_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1563\u001b[0m           if sparse_tensor_lib.is_sparse(t) else ops.convert_to_tensor(\n\u001b[1;32m   1564\u001b[0m               t, name=\"component_%d\" % i)\n\u001b[0;32m-> 1565\u001b[0;31m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1566\u001b[0m       ])\n\u001b[1;32m   1567\u001b[0m       \u001b[0mflat_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m       as_ref=False)\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1146\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    227\u001b[0m                                          as_ref=False):\n\u001b[1;32m    228\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[1;32m    206\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[1;32m    207\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[0;32m--> 208\u001b[0;31m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[1;32m    209\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[0;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    540\u001b[0m     raise TypeError(\n\u001b[1;32m    541\u001b[0m         \"Element type not supported in TensorProto: %s\" % numpy_dtype.name)\n\u001b[0;32m--> 542\u001b[0;31m   \u001b[0mappend_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_proto\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtensorflow/python/framework/fast_tensor_util.pyx\u001b[0m in \u001b[0;36mtensorflow.python.framework.fast_tensor_util.AppendObjectArrayToTensorProto\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow/python/util/compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[0;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[1;32m     59\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[0;32m---> 61\u001b[0;31m                     (bytes_or_text,))\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected binary or unicode string, got [1, 2]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# 变长\n",
    "\n",
    "# input_x = [np.asarray([1,2,3]), np.asarray([4,5]),[6], [7,8], [9]]\n",
    "input_x = [[1,2],[4,5,6],[7,8,9]]\n",
    "# input_x = np.asarray(input_x)\n",
    "# input_x = np.asarray(range(0, 18))\n",
    "input_y = input_x\n",
    "\n",
    "data_loader = tf.data.Dataset.from_tensor_slices(\n",
    "    {'text': np.asarray(input_x),\n",
    "     'label': np.asarray(input_y)}).batch(2)\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "iterator = data_loader.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        sample_batched = session.run(one_element)\n",
    "        inputs = sample_batched['text']\n",
    "        labels = sample_batched['label']\n",
    "        print(\">>> inputs\", inputs)\n",
    "        print(\">>> labels\", labels)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      ">>> inputs [[[  0   1   2]\n",
      "  [  3   4   5]\n",
      "  [  6   7   8]\n",
      "  [  9  10  11]\n",
      "  [ 12  13  14]\n",
      "  [ 15  16  17]]\n",
      "\n",
      " [[ 18  19  20]\n",
      "  [ 21  22  23]\n",
      "  [ 24  25  26]\n",
      "  [ 27  28  29]\n",
      "  [ 30  31  32]\n",
      "  [ 33  34  35]]\n",
      "\n",
      " [[ 36  37  38]\n",
      "  [ 39  40  41]\n",
      "  [ 42  43  44]\n",
      "  [ 45  46  47]\n",
      "  [ 48  49  50]\n",
      "  [ 51  52  53]]\n",
      "\n",
      " [[ 54  55  56]\n",
      "  [ 57  58  59]\n",
      "  [ 60  61  62]\n",
      "  [ 63  64  65]\n",
      "  [ 66  67  68]\n",
      "  [ 69  70  71]]\n",
      "\n",
      " [[ 72  73  74]\n",
      "  [ 75  76  77]\n",
      "  [ 78  79  80]\n",
      "  [ 81  82  83]\n",
      "  [ 84  85  86]\n",
      "  [ 87  88  89]]\n",
      "\n",
      " [[ 90  91  92]\n",
      "  [ 93  94  95]\n",
      "  [ 96  97  98]\n",
      "  [ 99 100 101]\n",
      "  [102 103 104]\n",
      "  [105 106 107]]\n",
      "\n",
      " [[108 109 110]\n",
      "  [111 112 113]\n",
      "  [114 115 116]\n",
      "  [117 118 119]\n",
      "  [120 121 122]\n",
      "  [123 124 125]]\n",
      "\n",
      " [[126 127 128]\n",
      "  [129 130 131]\n",
      "  [132 133 134]\n",
      "  [135 136 137]\n",
      "  [138 139 140]\n",
      "  [141 142 143]]]\n",
      ">>> labels [[[  0   1   2]\n",
      "  [  3   4   5]\n",
      "  [  6   7   8]\n",
      "  [  9  10  11]\n",
      "  [ 12  13  14]\n",
      "  [ 15  16  17]]\n",
      "\n",
      " [[ 18  19  20]\n",
      "  [ 21  22  23]\n",
      "  [ 24  25  26]\n",
      "  [ 27  28  29]\n",
      "  [ 30  31  32]\n",
      "  [ 33  34  35]]\n",
      "\n",
      " [[ 36  37  38]\n",
      "  [ 39  40  41]\n",
      "  [ 42  43  44]\n",
      "  [ 45  46  47]\n",
      "  [ 48  49  50]\n",
      "  [ 51  52  53]]\n",
      "\n",
      " [[ 54  55  56]\n",
      "  [ 57  58  59]\n",
      "  [ 60  61  62]\n",
      "  [ 63  64  65]\n",
      "  [ 66  67  68]\n",
      "  [ 69  70  71]]\n",
      "\n",
      " [[ 72  73  74]\n",
      "  [ 75  76  77]\n",
      "  [ 78  79  80]\n",
      "  [ 81  82  83]\n",
      "  [ 84  85  86]\n",
      "  [ 87  88  89]]\n",
      "\n",
      " [[ 90  91  92]\n",
      "  [ 93  94  95]\n",
      "  [ 96  97  98]\n",
      "  [ 99 100 101]\n",
      "  [102 103 104]\n",
      "  [105 106 107]]\n",
      "\n",
      " [[108 109 110]\n",
      "  [111 112 113]\n",
      "  [114 115 116]\n",
      "  [117 118 119]\n",
      "  [120 121 122]\n",
      "  [123 124 125]]\n",
      "\n",
      " [[126 127 128]\n",
      "  [129 130 131]\n",
      "  [132 133 134]\n",
      "  [135 136 137]\n",
      "  [138 139 140]\n",
      "  [141 142 143]]]\n",
      ">>> inputs [[[144 145 146]\n",
      "  [147 148 149]\n",
      "  [150 151 152]\n",
      "  [153 154 155]\n",
      "  [156 157 158]\n",
      "  [159 160 161]]\n",
      "\n",
      " [[162 163 164]\n",
      "  [165 166 167]\n",
      "  [168 169 170]\n",
      "  [171 172 173]\n",
      "  [174 175 176]\n",
      "  [177 178 179]]]\n",
      ">>> labels [[[144 145 146]\n",
      "  [147 148 149]\n",
      "  [150 151 152]\n",
      "  [153 154 155]\n",
      "  [156 157 158]\n",
      "  [159 160 161]]\n",
      "\n",
      " [[162 163 164]\n",
      "  [165 166 167]\n",
      "  [168 169 170]\n",
      "  [171 172 173]\n",
      "  [174 175 176]\n",
      "  [177 178 179]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "input_x = np.asarray(range(0, 180)).reshape(10,6,3)\n",
    "\n",
    "print(type(input_x))\n",
    "print(type(input_x[0]))\n",
    "print(type(input_x[0][0]))\n",
    "\n",
    "input_y = input_x\n",
    "\n",
    "data_loader = tf.data.Dataset.from_tensor_slices(\n",
    "    {'text': np.asarray(input_x),\n",
    "     'label': np.asarray(input_y)}).batch(8)\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "iterator = data_loader.make_one_shot_iterator()\n",
    "one_element = iterator.get_next()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        sample_batched = session.run(one_element)\n",
    "        inputs = sample_batched['text']\n",
    "        labels = sample_batched['label']\n",
    "        print(\">>> inputs\", inputs)\n",
    "        print(\">>> labels\", labels)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [1, 2, 3], [1, 2, 3]]\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [a, a, a]\n",
    "print(b)\n",
    "print(type(b))\n",
    "print(type(np.asarray(b)))\n",
    "print(type(b))\n",
    "print(type(b[0]))\n",
    "print(type(b[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [1, 2, 3], [1, 2, 3]]\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'int'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [a, a, a]\n",
    "print(b)\n",
    "print(type(b))\n",
    "print(type(np.array(b)))\n",
    "c = np.array(b)\n",
    "print(type(b))\n",
    "print(type(b[0]))\n",
    "print(type(b[0][0]))\n",
    "print(type(c))\n",
    "print(type(c[0]))\n",
    "print(type(c[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [1, 2, 3], [1, 2, 3]]\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'int'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.int64'>\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "b = [a, a, a]\n",
    "print(b)\n",
    "print(type(b))\n",
    "print(type(np.asarray(b)))\n",
    "c = np.asarray(b)\n",
    "print(type(b))\n",
    "print(type(b[0]))\n",
    "print(type(b[0][0]))\n",
    "print(type(c))\n",
    "print(type(c[0]))\n",
    "print(type(c[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
